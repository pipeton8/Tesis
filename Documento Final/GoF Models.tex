\documentclass[english, a4paper,12pt]{article}

%:Preamble
%:	Packages
\usepackage[bookmarks, colorlinks=true, allcolors=blue, pagebackref=true, hyperfootnotes=false]{hyperref}
\usepackage[eng]{felipito}
\usepackage[round]{natbib}

%:	Graphics path
\graphicspath{{./Graphics/}}

%:	Dimensions and spacing
\textheight = 690pt
\topmargin = -40pt
\textwidth = 500pt
\oddsidemargin = -22pt
\spacing{1.2}

%:	Epigraph settings
\setlength{\epigraphwidth}{0.59\textwidth}

%:	Title page content
\author{Felipe Del Canto M.}
\title{Goodness-of-fit in economic models \\ ?`How much are we losing?}
\date{November smth, 2019}

%:Document
\begin{document}

%:	Title page
\maketitle
\thispagestyle{empty}

%:	Abstract

\vfill
\epigraph{(...) all models are approximations. Essentially, all models are wrong, but some are useful. However, %
the approximate nature of the model must always be borne in mind.}{\textit{Empirical Model-Building and Response Surfaces (1987)} \\ \textsc{George Box and Norman Draper}}

\vfill
\abstract{Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Dolor sed viverra ipsum nunc aliquet bibendum enim. In massa tempor nec feugiat. Nunc aliquet bibendum enim facilisis gravida. Nisl nunc mi ipsum faucibus vitae aliquet nec ullamcorper. Amet luctus venenatis lectus magna fringilla. Volutpat maecenas volutpat blandit aliquam etiam erat velit scelerisque in. Egestas egestas fringilla phasellus faucibus scelerisque eleifend. Sagittis orci a scelerisque purus semper eget duis. Nulla pharetra diam sit amet nisl suscipit. Sed adipiscing diam donec adipiscing tristique risus nec feugiat in. Fusce ut placerat orci nulla. Pharetra vel turpis nunc eget lorem dolor. Tristique senectus et netus et malesuada.}
\vfill

\spacing{1.5}

\newpage
%%%	Introduction	%%%
\section{Introduction}

%:	General importance of models in science and in economics. The assumptions problem and measuring GoF
Every model in science is by definition a simplified reality. On the bright side, abstracting from the complexity of the real world has allowed society to understand the sometimes subtle mechanisms that rule nature and human behavior. This doesn't mean that a model is useful for every purpose. Evidently, whilst some of them may be very useful to expose certain dynamics of the real world, the approximation may carry errors that harm future predictions. The previous comment points directly to the question of which model is the most useful for some given problem. In particular, when the answer is \textit{many} the modeler needs to make a choice based on the results she expects to highlight and the channels to study. The dilemma is by no means alien to the field of economics. When describing an economy, the modeler is faced with several possible assumptions that shape the complexity of the model. Although some of them may be made by feasibility reasons (for example, because a highly detailed model can't be solved or simulated or because data won't be available to calibrate it) there may be others that serve a transparency purpose, that is, they intend to make clear the results without dwelling on the unnecessary details. Consequently, in the process of constructing a model, the investigator may choose to follow the Occam's Razor principle: among the models that are consistent with the evidence, choose the one that makes the fewest assumptions possible. It is implied by this criterion that the measure of a (correct) model is its complexity. However, as Milton Friedman said, ``The ultime goal of a positive science is the development of a `theory' or, `hypothesis' that yields valid and meaningful (...) predictions about phenomena not yet observed'' and thus ``Its performance is to be judged by the precision, scope, and conformity with experience of the predictions it yields''.\footnote{\cite{FriedmanPositive}.}

%: Related literature that supports relevance
Different strands in the economic literature have studied when predictions of some models are robust to different specifications. In \cite{SuttonMarketStruct}, the author discuss which mechanisms in the context of industrial organization still hold in conditions outside the classical models of, for example, Cournot and Bertrand. A similar motivation can be found in \cite{Morris97}, where they study how sensitive game theory conclusions are to the assumption of common knowledge of payoffs in a game. The interest in robustness in the context of mechanism design can be also found in \cite{Morris2011}. An interesting approach is the one in \cite{Basu97} where the authors try to estimate discrepancies due to ``aggregation effects'' when considering a model with a representative firm and one where heterogeneous effects are considered. Similarly, in \cite{SchoolAggregation} the authors try to reconcile contradictory results in the school literature arguing an important role of aggregation in the magnitude of omitted variable bias, which can in principle invalidate previous estimations. Related to these aggregation literature there is a concern with models that make use of aggregated data and different authors have studied what is called ``aggregation bias'' arguing that these models hide important mechanisms that could explain these differences.\footnote{See for example \cite{Agg1, Agg2, Agg3, Agg4}.}  

%:	Representative agent model problems (critics?)
Back to the economic theory, consider the example of the representative agent model. The assumption that there is only one consumer in the economy is useful and has been key to understand important qualitative results, especially in macroeconomics. Nevertheless, employing this model to predict future realizations of certain key variables such as aggregate demand or marginal propensity to consume (MPC) may be inaccurate if heterogeneity effects are in place. In other words, there is a shadow price in the approximation (which the investigator could be willing to pay or not) if she wishes to use the model for another, more quantitative-driven purpose. This point is made clearly in \cite{CarrollRequiem} in the context of the buffer-stock model: ``Representative-agent models are typically calibrated to match an aggregate wealth-to-income ratio'' but ``the typical householdâ€™s wealth is much smaller than the wealth of such a representative agent (...), this would lead one to expect that the behavior of the median household may not resemble the behavior of a representative agent with a wealth-to-income ratio similar to the aggregate ratio''. The evidence quickly backs up this view: while the annual MPC predicted by the representative agent model is about 0.04, many empirical analysis estimate this parameter to lie between 0.2 and 0.5.\footnote{\cite{CarrollRequiem}.} 

%:	Aggregation in particular and the idea
The aforementioned model is a particular case of a common practice in economics: aggregation. The other canonical example of its use is aggregation across goods, where instead of describing the myriad of goods available in an economy they are grouped into one or several categories. Regarding these two implementations, previous theoretical literature focused in one side of the problem: when is it possible to carry out this practice and describe precisely the same economy. In the case of the representative agent, the necessary and sufficient condition is that the indirect utility function of every consumer has the Gorman form.\footnote{\cite{Gorman53}.} When aggregation is applied to goods, the answer has been more elusive but two results arise. First, the Hicks-Leontief (composite commodity) theorem allows aggregation if relative prices are constant in the group of goods that are to be bundled. \footnote{\cite{Leontief36, HicksBook}.} Although a somewhat weaker requirement is proposed by \cite{Lewbel96}: bundling is possible if all group relative prices are independent of price indexes and income. The second answer states that grouping some goods is possible if preferences between them are ``independent'' of the remaining goods present in the economy.\footnote{See for example \cite{GormanSeparability}.} For the two kinds of aggregation, the conditions are highly restrictive and not typically met in econometric or theoretical applications. As mentioned previously, the literature has used them both in constructing models and making econometric estimations and this practice comes at a cost. Thus, understand and quantify possible approximation errors is crucial to determine and measure their goodness-of-fit. In contrast with some of the articles mentioned earlier, in this work I intend to give a theoretical look at how these deviations appear using simple models and try to bound them in terms of available variables in the economy. Next, drawing on the previous results, I will discuss a methodology about approaching this problem in more general settings.

%:	Index
The rest of the paper proceeds as follows. In \Cref{sec:repagent}, I present the first results bounding the prediction error in the case of a representative agent model. \rojo{Blabla}. Finally, in \Cref{sec:conclusion} I discuss some final thoughts about model fitness.

%%%	Aggregation across consumers	%%%
\section{Aggregation across consumers} \label{sec:repagent}


%%%	Concluding remarks		%%%
\section{Concluding remarks} \label{sec:conclusion}

%: 	Bibliography
\bibliographystyle{abbrvnat}
\bibliography{references}

\end{document}